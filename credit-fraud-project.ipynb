{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T16:38:12.278557Z","iopub.execute_input":"2024-08-23T16:38:12.279010Z","iopub.status.idle":"2024-08-23T16:38:12.294169Z","shell.execute_reply.started":"2024-08-23T16:38:12.278970Z","shell.execute_reply":"2024-08-23T16:38:12.292724Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T14:53:32.610321Z","iopub.execute_input":"2024-08-23T14:53:32.611640Z","iopub.status.idle":"2024-08-23T14:53:36.602669Z","shell.execute_reply.started":"2024-08-23T14:53:32.611578Z","shell.execute_reply":"2024-08-23T14:53:36.601554Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T14:53:44.900897Z","iopub.execute_input":"2024-08-23T14:53:44.901311Z","iopub.status.idle":"2024-08-23T14:53:45.387262Z","shell.execute_reply.started":"2024-08-23T14:53:44.901272Z","shell.execute_reply":"2024-08-23T14:53:45.385986Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.168375e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.074095e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.487313e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.213481e-16</td>\n      <td>-2.406331e-15</td>\n      <td>...</td>\n      <td>1.654067e-16</td>\n      <td>-3.568593e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.473266e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.683437e-15</td>\n      <td>-3.660091e-16</td>\n      <td>-1.227390e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#checking for missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T14:53:53.487070Z","iopub.execute_input":"2024-08-23T14:53:53.487490Z","iopub.status.idle":"2024-08-23T14:53:53.509636Z","shell.execute_reply.started":"2024-08-23T14:53:53.487451Z","shell.execute_reply":"2024-08-23T14:53:53.508468Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#Let's see how many frauds are there in the original dataset\nfrauds = (df['Class'].value_counts()[1]) / len(df)\nno_frauds = df['Class'].value_counts()[0] / len(df)\n\nprint(f'The fraction of frauds is {frauds}')\nprint(f'The fraction of non-fraud transactions is {no_frauds}')","metadata":{"execution":{"iopub.status.busy":"2024-08-23T14:54:03.365440Z","iopub.execute_input":"2024-08-23T14:54:03.365907Z","iopub.status.idle":"2024-08-23T14:54:03.393190Z","shell.execute_reply.started":"2024-08-23T14:54:03.365864Z","shell.execute_reply":"2024-08-23T14:54:03.391886Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The fraction of frauds is 0.001727485630620034\nThe fraction of non-fraud transactions is 0.9982725143693799\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This dataset is heavily imbalanced. It is showing 99.8% to be nonfraud transactions while only 0.17% of them are fraudulent.\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 5))\ncolor_palette = ['#FF0000', '#0000FF']\nsns.countplot(data = df['Class'], palette = color_palette)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T14:55:00.509181Z","iopub.execute_input":"2024-08-23T14:55:00.509808Z","iopub.status.idle":"2024-08-23T14:55:00.811401Z","shell.execute_reply.started":"2024-08-23T14:55:00.509762Z","shell.execute_reply":"2024-08-23T14:55:00.810054Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:12:11.747870Z","iopub.execute_input":"2024-08-23T16:12:11.748580Z","iopub.status.idle":"2024-08-23T16:12:11.759411Z","shell.execute_reply.started":"2024-08-23T16:12:11.748533Z","shell.execute_reply":"2024-08-23T16:12:11.757805Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n       'Class'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"# **STEPS TO HANDLE THE IMBALANCED DATASET**","metadata":{}},{"cell_type":"markdown","source":"**First, we need to scale the 'Time\" and 'Amount' columns. After doing so, we need to create a sub sample where the ratio of fraudulent to non-fraudulent transactions is 50/50**","metadata":{}},{"cell_type":"code","source":"#Scaling the Time and Amount columns\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\nstdscale = StandardScaler()\n\ndf['Amount Scaled'] = stdscale.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['Time Scaled'] = stdscale.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:20:12.400121Z","iopub.execute_input":"2024-08-23T16:20:12.400591Z","iopub.status.idle":"2024-08-23T16:20:12.512994Z","shell.execute_reply.started":"2024-08-23T16:20:12.400548Z","shell.execute_reply":"2024-08-23T16:20:12.512050Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:20:43.522898Z","iopub.execute_input":"2024-08-23T16:20:43.523325Z","iopub.status.idle":"2024-08-23T16:20:43.552768Z","shell.execute_reply.started":"2024-08-23T16:20:43.523286Z","shell.execute_reply":"2024-08-23T16:20:43.551348Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"         V1        V2        V3        V4        V5        V6        V7  \\\n0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10  ...       V22       V23       V24       V25  \\\n0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Class  Amount Scaled  Time Scaled  \n0 -0.189115  0.133558 -0.021053      0       0.244964    -1.996583  \n1  0.125895 -0.008983  0.014724      0      -0.342475    -1.996583  \n2 -0.139097 -0.055353 -0.059752      0       1.160686    -1.996562  \n3 -0.221929  0.062723  0.061458      0       0.140534    -1.996562  \n4  0.502292  0.219422  0.215153      0      -0.073403    -1.996541  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n      <th>Amount Scaled</th>\n      <th>Time Scaled</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>...</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0</td>\n      <td>0.244964</td>\n      <td>-1.996583</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>...</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>0</td>\n      <td>-0.342475</td>\n      <td>-1.996583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>...</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>0</td>\n      <td>1.160686</td>\n      <td>-1.996562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>...</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0</td>\n      <td>0.140534</td>\n      <td>-1.996562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>...</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>0</td>\n      <td>-0.073403</td>\n      <td>-1.996541</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Check the distribution of the target variable\nprint('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100, 2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100, 2), '% of the dataset')\n\n# Split the data into features (X) and target (y)\nX = df.drop('Class', axis=1)\ny = df['Class']\n\n# Stratified split to maintain the distribution of the target variable\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Check the distribution of the labels after splitting\ntrain_unique_label, train_counts_label = np.unique(y_train, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(y_test, return_counts=True)\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label / len(y_train))\nprint(test_counts_label / len(y_test))\n\n# If you need to convert the data to arrays\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:25:49.905766Z","iopub.execute_input":"2024-08-23T16:25:49.906324Z","iopub.status.idle":"2024-08-23T16:25:50.175266Z","shell.execute_reply.started":"2024-08-23T16:25:49.906281Z","shell.execute_reply":"2024-08-23T16:25:50.173710Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"No Frauds 99.83 % of the dataset\nFrauds 0.17 % of the dataset\n----------------------------------------------------------------------------------------------------\nLabel Distributions: \n\n[0.99827075 0.00172925]\n[0.99827955 0.00172045]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creating subsamples\ndf = df.sample(frac=1)\n\nfraud_df = df.loc[df['Class'] == 1]\nnon_fraud_df = df.loc[df['Class'] == 0][:492]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:28:23.537390Z","iopub.execute_input":"2024-08-23T16:28:23.537889Z","iopub.status.idle":"2024-08-23T16:28:23.696736Z","shell.execute_reply.started":"2024-08-23T16:28:23.537844Z","shell.execute_reply":"2024-08-23T16:28:23.695602Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"               V1        V2         V3        V4         V5        V6  \\\n51117    1.045519 -0.198129   0.463271  0.656987  -0.204973  0.544898   \n150925 -13.512074  8.215177 -16.582606  6.207369 -11.318472 -2.997207   \n80264   -1.195452  0.892639   0.993388 -1.224040   0.202102 -0.234394   \n191267   0.290155  0.049243  -0.740524  2.865463   1.395294 -0.535163   \n249239  -0.082983 -3.935919  -2.616709  0.163310  -1.400952 -0.809419   \n\n               V7        V8        V9        V10  ...       V22       V23  \\\n51117   -0.278360  0.311150  0.275163  -0.110890  ... -0.199765  0.041696   \n150925 -17.640470  0.040349 -5.620232 -15.123752  ...  1.514028 -0.141879   \n80264    0.346618  0.365721 -0.247206  -0.211964  ...  0.057799  0.032770   \n191267   0.142543 -0.222770 -1.463691   1.713538  ...  1.018191  0.303550   \n249239   1.501580 -0.471000  1.519743  -1.134454  ... -0.182305 -0.921017   \n\n             V24       V25       V26       V27       V28  Class  \\\n51117  -0.268410  0.247087  0.309925 -0.001882 -0.000268      0   \n150925  0.789186 -0.031343 -0.255057 -1.865831 -0.442204      1   \n80264  -0.275531 -0.380194  0.749984 -0.271347 -0.133850      0   \n191267  0.833886 -1.222306  2.745261 -0.220402  0.168233      1   \n249239  0.111635 -0.071622 -1.125881 -0.170947  0.126221      1   \n\n        Amount Scaled  Time Scaled  \n51117       -0.210818    -1.053104  \n150925      -0.171396    -0.014169  \n80264       -0.349231    -0.766695  \n191267      -0.324523     0.723806  \n249239       4.032631     1.252844  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n      <th>Amount Scaled</th>\n      <th>Time Scaled</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51117</th>\n      <td>1.045519</td>\n      <td>-0.198129</td>\n      <td>0.463271</td>\n      <td>0.656987</td>\n      <td>-0.204973</td>\n      <td>0.544898</td>\n      <td>-0.278360</td>\n      <td>0.311150</td>\n      <td>0.275163</td>\n      <td>-0.110890</td>\n      <td>...</td>\n      <td>-0.199765</td>\n      <td>0.041696</td>\n      <td>-0.268410</td>\n      <td>0.247087</td>\n      <td>0.309925</td>\n      <td>-0.001882</td>\n      <td>-0.000268</td>\n      <td>0</td>\n      <td>-0.210818</td>\n      <td>-1.053104</td>\n    </tr>\n    <tr>\n      <th>150925</th>\n      <td>-13.512074</td>\n      <td>8.215177</td>\n      <td>-16.582606</td>\n      <td>6.207369</td>\n      <td>-11.318472</td>\n      <td>-2.997207</td>\n      <td>-17.640470</td>\n      <td>0.040349</td>\n      <td>-5.620232</td>\n      <td>-15.123752</td>\n      <td>...</td>\n      <td>1.514028</td>\n      <td>-0.141879</td>\n      <td>0.789186</td>\n      <td>-0.031343</td>\n      <td>-0.255057</td>\n      <td>-1.865831</td>\n      <td>-0.442204</td>\n      <td>1</td>\n      <td>-0.171396</td>\n      <td>-0.014169</td>\n    </tr>\n    <tr>\n      <th>80264</th>\n      <td>-1.195452</td>\n      <td>0.892639</td>\n      <td>0.993388</td>\n      <td>-1.224040</td>\n      <td>0.202102</td>\n      <td>-0.234394</td>\n      <td>0.346618</td>\n      <td>0.365721</td>\n      <td>-0.247206</td>\n      <td>-0.211964</td>\n      <td>...</td>\n      <td>0.057799</td>\n      <td>0.032770</td>\n      <td>-0.275531</td>\n      <td>-0.380194</td>\n      <td>0.749984</td>\n      <td>-0.271347</td>\n      <td>-0.133850</td>\n      <td>0</td>\n      <td>-0.349231</td>\n      <td>-0.766695</td>\n    </tr>\n    <tr>\n      <th>191267</th>\n      <td>0.290155</td>\n      <td>0.049243</td>\n      <td>-0.740524</td>\n      <td>2.865463</td>\n      <td>1.395294</td>\n      <td>-0.535163</td>\n      <td>0.142543</td>\n      <td>-0.222770</td>\n      <td>-1.463691</td>\n      <td>1.713538</td>\n      <td>...</td>\n      <td>1.018191</td>\n      <td>0.303550</td>\n      <td>0.833886</td>\n      <td>-1.222306</td>\n      <td>2.745261</td>\n      <td>-0.220402</td>\n      <td>0.168233</td>\n      <td>1</td>\n      <td>-0.324523</td>\n      <td>0.723806</td>\n    </tr>\n    <tr>\n      <th>249239</th>\n      <td>-0.082983</td>\n      <td>-3.935919</td>\n      <td>-2.616709</td>\n      <td>0.163310</td>\n      <td>-1.400952</td>\n      <td>-0.809419</td>\n      <td>1.501580</td>\n      <td>-0.471000</td>\n      <td>1.519743</td>\n      <td>-1.134454</td>\n      <td>...</td>\n      <td>-0.182305</td>\n      <td>-0.921017</td>\n      <td>0.111635</td>\n      <td>-0.071622</td>\n      <td>-1.125881</td>\n      <td>-0.170947</td>\n      <td>0.126221</td>\n      <td>1</td>\n      <td>4.032631</td>\n      <td>1.252844</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Distribution in the new dataframe\nfraud2 = new_df['Class'].value_counts()[1] / len(new_df)\nnonfraud2 = new_df['Class'].value_counts()[0] / len(new_df)\n\nprint(f'Fraudulent Transactions : {fraud2} \\nNon-Fraud : {nonfraud2}')","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:32:26.537056Z","iopub.execute_input":"2024-08-23T16:32:26.537439Z","iopub.status.idle":"2024-08-23T16:32:26.545273Z","shell.execute_reply.started":"2024-08-23T16:32:26.537405Z","shell.execute_reply":"2024-08-23T16:32:26.544039Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Fraudulent Transactions : 0.5 \nNon-Fraud : 0.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Therefore, a sub sample with 50-50 ratio has been successfully created","metadata":{}},{"cell_type":"code","source":"X_subsample = new_df.drop('Class', axis=1)\ny_subsample = new_df['Class']\n\n# Perform a stratified split on the new subsample if needed\nX_train_subsample, X_test_subsample, y_train_subsample, y_test_subsample = train_test_split(\n    X_subsample, y_subsample, test_size=0.2, random_state=42, stratify=y_subsample\n)\n\nX_train_subsample = X_train_subsample.values\nX_test_subsample = X_test_subsample.values\ny_train_subsample = y_train_subsample.values\ny_test_subsample = y_test_subsample.values","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:51:22.982265Z","iopub.execute_input":"2024-08-23T16:51:22.982741Z","iopub.status.idle":"2024-08-23T16:51:22.995659Z","shell.execute_reply.started":"2024-08-23T16:51:22.982683Z","shell.execute_reply":"2024-08-23T16:51:22.994292Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# RANDOM FOREST CLASSIFIER IMPLEMENTATION FROM SCRATCH","metadata":{}},{"cell_type":"code","source":"#Implementing Random Forest Classifiers from Scratch\n\nfrom collections import Counter\nfrom sklearn.utils import resample\n\n#First implementing the Decision Tree\nclass DecisionTreeNode:\n    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n        # DIY\n        self.feature_index = feature_index\n        self.threshold = threshold\n        self.left = left\n        self.right = right\n        self.value = value\n\n        return None\n    \n    \nclass DecisionTree:\n    def __init__(self, min_samples_split=2, max_depth=2):\n        self.root = None\n        self.min_samples_split = min_samples_split\n        self.max_depth = max_depth\n\n    def fit(self, X, y):\n        self.root = self._grow_tree(X, y)\n\n    def _grow_tree(self, X, y, depth=0):\n        n_samples, n_features = X.shape\n        n_labels = len(np.unique(y))\n\n        # Check the stopping criteria\n\n        if depth >= self.max_depth or n_samples < self.min_samples_split or n_labels == 1:\n            leaf_value = self._most_common_label(y)\n            return DecisionTreeNode(value=leaf_value)\n\n        # Find the best split\n        best_split = self._best_split(X, y, n_features)\n        if not best_split:\n          leaf_value = self._most_common_label(y)\n          return DecisionTreeNode(value=leaf_value)\n\n\n        # Grow the children recursively\n        left_indices, right_indices = self._split(X[:, best_split['feature_index']], best_split['threshold'])\n        left_subtree = self._grow_tree(X[left_indices, :], y[left_indices], depth + 1)\n        right_subtree = self._grow_tree(X[right_indices, :], y[right_indices], depth + 1)\n        return DecisionTreeNode(best_split['feature_index'], best_split['threshold'], left_subtree, right_subtree)\n\n\n    def _best_split(self, X, y, n_features):\n        best_split = {}\n        max_info_gain = -float(\"inf\")\n\n        for f_index in range(n_features):\n          col = X[:, f_index]\n          threshold_l = np.unique(col)\n          for t in threshold_l:\n            left_indices, right_indices = self._split(col, t)\n            y_left = y[left_indices]\n            y_right = y[right_indices]\n\n            info_gain = self._information_gain(y, y_left, y_right)\n\n            if info_gain > max_info_gain:\n              best_split = {'feature_index': f_index, 'threshold': t}\n              max_info_gain = info_gain\n\n        return best_split if max_info_gain > 0 else None\n\n    # Define THE SPLIT\n    def _split(self, X_column, threshold):\n\n        left_indices = []\n        right_indices = []\n        for i in range(len((X_column))):\n            if X_column[i] <= threshold:\n                left_indices.append(i)\n            else:\n                right_indices.append(i)\n        return left_indices, right_indices\n\n    # Calculate Information Gain\n    def _information_gain(self, y, y_left, y_right):\n\n        total_samples = len(y)\n        left_samples = len(y_left)\n        right_samples = len(y_right)\n        left_proportion = left_samples / total_samples\n        right_proportion = right_samples / total_samples\n        gain = self._entropy(y) - (left_proportion * self._entropy(y_left) + right_proportion * self._entropy(y_right))\n        return gain\n\n    # Calculate Entropy\n    def _entropy(self, y):\n\n        ps = np.bincount(y) / len(y)\n        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n\n\n\n    def _most_common_label(self, y):\n        return np.bincount(y.astype(int)).argmax()\n\n    def predict(self, X):\n        return np.array([self._traverse_tree(x, self.root) for x in X])\n\n    def _traverse_tree(self, x, node):\n        if node.value is not None:\n            return node.value\n        if x[node.feature_index] <= node.threshold:\n            return self._traverse_tree(x, node.left)\n        return self._traverse_tree(x, node.right)\n\n    \n    \nclass RandomForest:\n    def __init__(self, n_trees=10, min_samples_split=2, max_depth=2, max_features=None):\n        self.n_trees = n_trees\n        self.min_samples_split = min_samples_split\n        self.max_depth = max_depth\n        self.max_features = max_features\n        self.trees = []\n\n    def fit(self, X, y):\n        self.trees = []\n        for _ in range(self.n_trees):\n            tree = DecisionTree(min_samples_split=self.min_samples_split, max_depth=self.max_depth)\n            # Bootstrap sampling\n            X_sample, y_sample = resample(X, y, replace=True)\n            # Train the tree\n            tree.fit(X_sample, y_sample)\n            self.trees.append(tree)\n\n    def predict(self, X):\n        # Aggregate predictions from all trees\n        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n        # Majority vote\n        return np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=tree_preds)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:53:21.785504Z","iopub.execute_input":"2024-08-23T16:53:21.785964Z","iopub.status.idle":"2024-08-23T16:53:21.809946Z","shell.execute_reply.started":"2024-08-23T16:53:21.785920Z","shell.execute_reply":"2024-08-23T16:53:21.808638Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#implementing RandomForest on the original\nclf = RandomForest(n_trees=10, min_samples_split=2, max_depth=3, max_features=None)\nclf.fit(X_train, y_train)\npredictions = rf.predict(X_test)\n\naccuracy_ = accuracy_score(y_test, predictions)\nprecision_ = precision_score(y_test, predictions)\nrecall_ = recall_score(y_test, predictions)\nf1_ = f1_score(y_test, predictions)\nconf_matrix_ = confusion_matrix(y_test, predictions)\n\nprint(f'Accuracy: {accuracy_}')\nprint(f'Precision: {precision_}')\nprint(f'Recall: {recall_}')\nprint(f'F1 Score: {f1_}')\nprint(f'Confusion Matrix:\\n{conf_matrix_}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#implementing RandomForest on the subsample\nrf = RandomForest(n_trees=10, min_samples_split=2, max_depth=3, max_features=None)\nrf.fit(X_train_subsample, y_train_subsample)\npredictions = rf.predict(X_test_subsample)\n\naccuracy = accuracy_score(y_test_subsample, predictions)\nprecision = precision_score(y_test_subsample, predictions)\nrecall = recall_score(y_test_subsample, predictions)\nf1 = f1_score(y_test_subsample, predictions)\nconf_matrix = confusion_matrix(y_test_subsample, predictions)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:53:24.556237Z","iopub.execute_input":"2024-08-23T16:53:24.557074Z","iopub.status.idle":"2024-08-23T16:54:36.541836Z","shell.execute_reply.started":"2024-08-23T16:53:24.557018Z","shell.execute_reply":"2024-08-23T16:54:36.540752Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy: {accuracy}')\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')\nprint(f'F1 Score: {f1}')\nprint(f'Confusion Matrix:\\n{conf_matrix}')","metadata":{"execution":{"iopub.status.busy":"2024-08-23T16:56:38.556080Z","iopub.execute_input":"2024-08-23T16:56:38.556491Z","iopub.status.idle":"2024-08-23T16:56:38.563236Z","shell.execute_reply.started":"2024-08-23T16:56:38.556455Z","shell.execute_reply":"2024-08-23T16:56:38.562116Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Accuracy: 0.9086294416243654\nPrecision: 0.9545454545454546\nRecall: 0.8571428571428571\nF1 Score: 0.9032258064516128\nConfusion Matrix:\n[[95  4]\n [14 84]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CONCLUSION\n* In this project, we explored the problem of fraud detection using a credit card transactions dataset. The initial dataset was highly imbalanced, with fraudulent transactions constituting only a small fraction of the total data. To address this, we created a balanced subsample where the fraud-to-non-fraud ratio was 50/50, enabling us to build a more effective model.\n\n* We implemented a Random Forest classifier from scratch, which was trained on both the balanced subsample and the imbalanced dataframe. The model's performance was evaluated on a test set for both, and the results were:\n\n1. Accuracy: The overall accuracy of the model was satisfactory, indicating that the model is effective in predicting the majority of transactions correctly.\n\n2. Precision: The precision score highlighted the model's ability to correctly identify fraudulent transactions among all the positive predictions, reducing the number of false positives.\n\n3. Recall: The recall score showed the model's effectiveness in identifying fraudulent transactions from the actual fraud cases, which is crucial in minimizing false negatives.\n\n4. F1 Score: The F1 score, which balances precision and recall, provided a comprehensive measure of the model's performance.\n\n5. Confusion Matrix: The confusion matrix further demonstrated the model's ability to distinguish between fraudulent and non-fraudulent transactions.\n\n* Overall, the custom Random Forest classifier performed well on the balanced dataset, showcasing the importance of data preprocessing and balancing in dealing with imbalanced datasets. The approach taken in this project can be applied to similar classification problems where class imbalance is a significant concern.\n\n* Future work could include exploring more advanced techniques such as hyperparameter tuning, feature selection, and ensemble methods to further enhance the model's performance. Additionally, applying this model to the original imbalanced dataset and comparing the results could provide further insights into the impact of data balancing on model performance.","metadata":{}}]}